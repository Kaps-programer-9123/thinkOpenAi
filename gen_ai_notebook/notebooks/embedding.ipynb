{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bb4b45",
   "metadata": {},
   "source": [
    "<h2> Best Open-Source Embedding Models (Local Use) </h2>\n",
    "\n",
    "| **Model**                | **Size**          | **Use Case**                          | **Library**               |\n",
    "| ------------------------ | ----------------- | ------------------------------------- | ------------------------- |\n",
    "| `all-MiniLM-L6-v2`       | \\~80MB            | General-purpose sentence embeddings   | SentenceTransformers      |\n",
    "| `E5-base` / `E5-small`   | \\~200MB / \\~100MB | Search, semantic similarity           | Hugging Face Transformers |\n",
    "| `Instructor XL`          | \\~1.5GB           | Task-specific embeddings with prompts | Hugging Face              |\n",
    "| `BGE-M3` / `BGE-base-en` | \\~400MB           | Versatile, multilingual embeddings    | Hugging Face              |\n",
    "| `mpnet-base-v2`          | \\~420MB           | Semantic search & clustering          | SentenceTransformers      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e7c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode sentences\n",
    "sentences = [\"This is a test.\", \"Embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d8e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reinforcement learning is...', 'Supervised learning is...']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "query = \"How does reinforcement learning work?\"\n",
    "candidates = [\"Reinforcement learning is...\", \"Supervised learning is...\"]\n",
    "\n",
    "scores = model.predict([(query, doc) for doc in candidates])\n",
    "top_docs = [doc for _, doc in sorted(zip(scores, candidates), reverse=True)]\n",
    "top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26303976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo is capital of Japan.\n",
      "Tokyo is in Japan.\n"
     ]
    }
   ],
   "source": [
    "import faiss #pip install faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model and encode documents\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "docs = [\"Paris is the capital of France.\", \"Berlin is in Germany.\", \"Tokyo is in Japan.\", \"Tokyo is capital of Japan.\"]\n",
    "doc_embeddings = model.encode(docs)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 = Euclidean distance (can use cosine too)\n",
    "\n",
    "index.add(doc_embeddings)  # Store embeddings\n",
    "\n",
    "# Encode query and search\n",
    "query = \"Capital of Japan\"\n",
    "query_embedding = model.encode([query])\n",
    "top_k = 2\n",
    "distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "# Show results\n",
    "for i in indices[0]:\n",
    "    print(docs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b49ba4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript runs in the browser. Score: 0.35208036468145\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "qdrant = QdrantClient(\":memory:\")  # In-memory, or use host='localhost'\n",
    "\n",
    "# Create collection\n",
    "qdrant.create_collection(\n",
    "    collection_name=\"docs\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "texts = [\"Python is great.\", \"JavaScript runs in the browser.\", \"C++ is powerful.\"]\n",
    "embeds = model.encode(texts)\n",
    "\n",
    "points = [\n",
    "    PointStruct(id=i, vector=embeds[i], payload={\"text\": texts[i]})\n",
    "    for i in range(len(texts))\n",
    "]\n",
    "qdrant.upsert(collection_name=\"docs\", points=points)\n",
    "\n",
    "# Query\n",
    "query = \"language used in frontend\"\n",
    "query_vec = model.encode(query)\n",
    "results = qdrant.query_points(collection_name=\"docs\", query=query_vec, limit=2)\n",
    "\n",
    "for r in results:\n",
    "    # print(r.payload[\"text\"], \"Score:\", r.score)\n",
    "    print(r[1][0].payload['text'],  \"Score:\", r[1][0].score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fffb4f",
   "metadata": {},
   "source": [
    "Implementation Steps for Reranking\n",
    "Using Cross-Encoder for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f24610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load cross-encoder model (this will perform query-document reranking)\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# Example query and retrieved documents\n",
    "query = \"What is the capital of France?\"\n",
    "retrieved_docs = [\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"France is a country in Europe.\",\n",
    "    \"Paris is known for its culture and landmarks.\",\n",
    "    \"The Eiffel Tower is located in Paris.\"\n",
    "]\n",
    "\n",
    "# Create query-document pairs (query + each retrieved document)\n",
    "pairs = [(query, doc) for doc in retrieved_docs]\n",
    "\n",
    "# Use the cross-encoder to get relevance scores for each pair\n",
    "scores = model.predict(pairs)\n",
    "\n",
    "# Sort documents based on the relevance score in descending order\n",
    "sorted_indices = np.argsort(scores)[::-1]  # Sort indices based on scores in descending order\n",
    "\n",
    "# Get the top-N documents based on reranking\n",
    "top_k_docs = [retrieved_docs[i] for i in sorted_indices[:2]]  # Top 2 most relevant documents\n",
    "\n",
    "# Display reranked documents\n",
    "print(\"Top-K Reranked Documents:\")\n",
    "for doc in top_k_docs:\n",
    "    print(doc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
