{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d055951",
   "metadata": {},
   "source": [
    "## üöÄ Best Local Open-Source Vector Databases (Vector Stores)\n",
    "\n",
    "| **Vector DB**       | **Size**     | **Features**                                                                 | **Language**     | **Persistence**       | **Best For**                                 |\n",
    "|---------------------|--------------|------------------------------------------------------------------------------|------------------|------------------------|-----------------------------------------------|\n",
    "| **FAISS**           | ~50MB        | Fast, supports L2/IP, GPU, quantization, mature ecosystem                   | Python / C++     | ‚úÖ Manual (save/load)  | Fast local similarity search                 |\n",
    "| **Annoy**           | ~15MB        | Tree-based, fast, static, no training needed                                | Python           | ‚úÖ Manual              | Small-to-medium fixed datasets               |\n",
    "| **HNSWlib**         | ~10MB        | Graph-based (HNSW), accurate, very low memory use                           | Python / C++     | ‚úÖ Manual              | Accurate local ANN search                    |\n",
    "| **ScaNN**           | ~80MB        | Optimized for inner product / cosine, from Google                           | Python / C++     | ‚úÖ Manual              | Cosine-heavy tasks, similarity search        |\n",
    "| **Chroma (local)**  | ~100MB       | Built-in persistence, metadata support, LangChain-compatible                | Python           | ‚úÖ Auto (persistent)   | RAG prototypes, local vector + metadata      |\n",
    "| **Qdrant (local)**  | ~250MB       | Fast, rich filters, Docker or embedded mode                                 | Rust / Python    | ‚úÖ Persistent          | Hybrid search (vector + metadata filters)    |\n",
    "| **Weaviate (embedded)** | ~200MB   | REST & GraphQL, local embedded mode, metadata filtering                     | Python / Go      | ‚úÖ Persistent          | Local + semantic + hybrid search             |\n",
    "| **Milvus (lite)**   | ~500MB+      | Distributed, scalable, requires Docker or cloud                             | C++ / Go         | ‚úÖ Persistent          | Large-scale production use                   |\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Notes:\n",
    "- ‚úÖ **Persistent** = Saves embeddings to disk and reloads after restart.\n",
    "- Use **FAISS, HNSWlib, or Annoy** for lightweight, local-only projects.\n",
    "- Use **Chroma, Qdrant, or Weaviate** for local RAG or metadata-rich search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fde159",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "# üß† Vector Database Comparison: FAISS, Qdrant, Weaviate, and Chroma\n",
    "\n",
    "This notebook covers:\n",
    "- Storing embeddings using `all-MiniLM-L6-v2`\n",
    "- Local use of FAISS, Qdrant, Weaviate, and Chroma\n",
    "- Similarity/distance search\n",
    "- Parametrized search types\n",
    "- Interview questions & differences\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Prerequisites\n",
    "\n",
    "```python\n",
    "!pip install sentence-transformers faiss-cpu qdrant-client weaviate-client chromadb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59765c",
   "metadata": {},
   "source": [
    "## ‚ú® Generate Embeddings with all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc15f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "documents = [\"Paris is the capital of France.\",\n",
    "             \"Berlin is in Germany.\", \n",
    "             \"Tokyo is in Japan.\", \n",
    "             \"Tokyo is capital of Japan.\",\n",
    "             \"kapil is gen ai engineer working for testing model\",\n",
    "             \"kapil works in gen Ai area\"]\n",
    "\n",
    "embeddings = model.encode(documents,show_progress_bar=True,output_value='sentence_embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b097cab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vector size for each sentense\n",
    "embeddings[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137c419",
   "metadata": {},
   "source": [
    "## üß† FAISS: Facebook AI Similarity Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9917aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices:\n",
      " [[0 1]\n",
      " [1 2]]\n",
      "Distances:\n",
      " [[0.        1.4986992]\n",
      " [0.        1.1811731]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embeddings_np = np.array(embeddings).astype('float32')\n",
    "index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "index.add(embeddings_np)\n",
    "\n",
    "\n",
    "D, I = index.search(embeddings_np[:2], k=2)\n",
    "print(\"Indices:\\n\", I)\n",
    "print(\"Distances:\\n\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe57a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  [[0.29537767 0.31994855]]\n",
      "indices :  [[3 2]]\n",
      "query : what is Tokyo\n",
      "Ans is : ->\n",
      "Tokyo is capital of Japan.\n",
      "Tokyo is in Japan.\n"
     ]
    }
   ],
   "source": [
    "#search nearest vector to query\n",
    "\n",
    "query = \"what is Tokyo\"\n",
    "embedded_query = model.encode([query])\n",
    "\n",
    "embedded_query.size\n",
    "\n",
    "distances, indices = index.search(embedded_query,k=2)\n",
    "\n",
    "print(\"distance : \",distances)\n",
    "print(\"indices : \",indices)\n",
    "\n",
    "print(\"query : what is Tokyo\")\n",
    "print(\"Ans is : ->\")\n",
    "for i in indices[0]:\n",
    "    print(documents[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5208b",
   "metadata": {},
   "source": [
    "## üìå Qdrant: With Metadata and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723b1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qdrant_client\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = qdrant_client.QdrantClient(path=\"qdrant_local\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name='docs',\n",
    "    vectors_config=VectorParams(size=embeddings_np.shape[1], distance=Distance.COSINE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6b10639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Tokyo is capital of Japan.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "payload = [{\"text\": doc} for doc in documents]\n",
    "\n",
    "client.upload_collection(\n",
    "    collection_name='docs',\n",
    "    vectors=embeddings_np,\n",
    "    payload=payload\n",
    ")\n",
    "\n",
    "query_vector = \"what is capital\"\n",
    "embedded_query_vector = model.encode(query_vector)\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name='docs',\n",
    "    query=embedded_query_vector,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(res[1][0].payload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e9abf",
   "metadata": {},
   "source": [
    "## üåê Weaviate: Graph + Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from weaviate import Client\n",
    "\n",
    "# client = Client(\"http://localhost:8080\")\n",
    "\n",
    "# # Schema\n",
    "# client.schema.delete_all()\n",
    "# client.schema.create_class({\n",
    "#     \"class\": \"Document\",\n",
    "#     \"vectorizer\": \"none\",\n",
    "#     \"properties\": [{\"name\": \"text\", \"dataType\": [\"text\"]}]\n",
    "# })\n",
    "\n",
    "# # Add\n",
    "# for doc, emb in zip(documents, embeddings_np):\n",
    "#     client.data_object.create({\"text\": doc}, \"Document\", vector=emb.tolist())\n",
    "\n",
    "# # Search\n",
    "# res = client.query.get(\"Document\", [\"text\"])\\\n",
    "#     .with_near_vector({\"vector\": embeddings_np[0].tolist()})\\\n",
    "#     .with_limit(2).do()\n",
    "# print(res)\n",
    "\n",
    "import weaviate\n",
    "print(weaviate.__file__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a73770",
   "metadata": {},
   "source": [
    "## ‚ö° Chroma: Lightweight & Pythonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703ab9a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- Initialize persistent Chroma client ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_db_impl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mduckdb+parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./chroma_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- Create or get a collection ---\u001b[39;00m\n\u001b[32m     11\u001b[39m collection_name = \u001b[33m\"\u001b[39m\u001b[33mdocs\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\__init__.py:371\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(settings, tenant, database)\u001b[39m\n\u001b[32m    368\u001b[39m tenant = \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[32m    369\u001b[39m database = \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\api\\client.py:63\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     59\u001b[39m     tenant: \u001b[38;5;28mstr\u001b[39m = DEFAULT_TENANT,\n\u001b[32m     60\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m     61\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     62\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mself\u001b[39m.tenant = tenant\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m.database = database\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:19\u001b[39m, in \u001b[36mSharedSystemClient.__init__\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     16\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m._identifier = SharedSystemClient._get_identifier_from_settings(settings)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mSharedSystemClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:26\u001b[39m, in \u001b[36mSharedSystemClient._create_system_if_not_exists\u001b[39m\u001b[34m(cls, identifier, settings)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_system_if_not_exists\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mcls\u001b[39m, identifier: \u001b[38;5;28mstr\u001b[39m, settings: Settings\n\u001b[32m     24\u001b[39m ) -> System:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._identifier_to_system:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         new_system = \u001b[43mSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mcls\u001b[39m._identifier_to_system[identifier] = new_system\n\u001b[32m     29\u001b[39m         new_system.instance(ProductTelemetryClient)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\config.py:385\u001b[39m, in \u001b[36mSystem.__init__\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# Validate settings don't contain any legacy config values\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _legacy_config_keys:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    386\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    389\u001b[39m     settings[\u001b[33m\"\u001b[39m\u001b[33mchroma_segment_cache_policy\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m settings[\u001b[33m\"\u001b[39m\u001b[33mchroma_segment_cache_policy\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mLRU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chetan chopade\\Desktop\\python_test_kapil\\llm_test\\venv\\Lib\\site-packages\\chromadb\\config.py:319\u001b[39m, in \u001b[36mSettings.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# Error on legacy config values\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m _legacy_config_values:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[31mValueError\u001b[39m: \u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# --- Initialize persistent Chroma client ---\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_data\"\n",
    "))\n",
    "\n",
    "# --- Create or get a collection ---\n",
    "collection_name = \"docs\"\n",
    "collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "# --- Add documents with embeddings ---\n",
    "for idx, (doc, emb) in enumerate(zip(documents, embeddings_np)):\n",
    "    collection.add(\n",
    "        documents=[doc],\n",
    "        metadatas=[{\"text\": doc}],\n",
    "        ids=[str(idx)],\n",
    "        embeddings=[emb.tolist()]\n",
    "    )\n",
    "\n",
    "# --- Perform a similarity query ---\n",
    "query_vector = embeddings_np[0].tolist()\n",
    "top_k = 2\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_vector],\n",
    "    n_results=top_k\n",
    ")\n",
    "\n",
    "# --- Display results ---\n",
    "for i, (doc, score) in enumerate(zip(results[\"documents\"][0], results[\"distances\"][0])):\n",
    "    print(f\"Result {i+1}: {doc} (Score: {score:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
